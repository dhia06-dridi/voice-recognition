{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1178ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• Using device: cuda\n",
      "\n",
      "‚öôÔ∏è Configuration Optimis√©e:\n",
      "   input_dropout: 0.15\n",
      "   feature_dropout: 0.35\n",
      "   classifier_dropout: 0.4\n",
      "   weight_decay: 0.005\n",
      "   label_smoothing: 0.1\n",
      "   learning_rate: 0.0005\n",
      "   batch_size: 32\n",
      "   num_epochs: 100\n",
      "   warmup_epochs: 5\n",
      "   n_mels: 128\n",
      "   n_fft: 2048\n",
      "   hop_length: 512\n",
      "   sample_rate: 16000\n",
      "   target_length: 16000\n",
      "   use_amp: True\n",
      "   aug_strength: 0.6\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: Configuration Optimis√©e\n",
    "# =============================================================================\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import timm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration GPU optimis√©e\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "print(f\"üî• Using device: {device}\")\n",
    "\n",
    "# Seed pour reproductibilit√©\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configuration optimis√©e\n",
    "class ModelConfig:\n",
    "    def __init__(self):\n",
    "        # Dropout configuration - OPTIMIS√â\n",
    "        self.input_dropout = 0.15\n",
    "        self.feature_dropout = 0.35  # R√©duit pour √©viter l'underfitting\n",
    "        self.classifier_dropout = 0.4\n",
    "        \n",
    "        # Training configuration - OPTIMIS√â\n",
    "        self.weight_decay = 0.005  # R√©duit pour plus de flexibilit√©\n",
    "        self.label_smoothing = 0.1\n",
    "        self.learning_rate = 5e-4  # Learning rate initial r√©duit\n",
    "        self.batch_size = 32  # Augment√© pour stabilit√©\n",
    "        self.num_epochs = 100\n",
    "        self.warmup_epochs = 5  # NOUVEAU: Warm-up du LR\n",
    "        \n",
    "        # Audio configuration - OPTIMIS√â\n",
    "        self.n_mels = 128\n",
    "        self.n_fft = 2048  # Augment√© pour meilleure r√©solution\n",
    "        self.hop_length = 512  # Ajust√© proportionnellement\n",
    "        self.sample_rate = 16000\n",
    "        self.target_length = 16000\n",
    "        \n",
    "        # Mixed Precision Training\n",
    "        self.use_amp = True  # NOUVEAU: Automatic Mixed Precision\n",
    "        \n",
    "        # Data augmentation strength\n",
    "        self.aug_strength = 0.6  # NOUVEAU: Contr√¥le de l'augmentation\n",
    "\n",
    "config = ModelConfig()\n",
    "\n",
    "print(\"\\n‚öôÔ∏è Configuration Optimis√©e:\")\n",
    "for key, value in config.__dict__.items():\n",
    "    print(f\"   {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db58b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: Early Stopping et Augmentation Am√©lior√©s\n",
    "# =============================================================================\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=15, min_delta=0.0005, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_loss = None\n",
    "        self.best_acc = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.best_model_state = None\n",
    "        self.best_epoch = 0\n",
    "        \n",
    "    def __call__(self, val_loss, val_acc, model, epoch):\n",
    "        # Crit√®re combin√©: am√©lioration de la loss OU de l'accuracy\n",
    "        improved = False\n",
    "        \n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_acc = val_acc\n",
    "            self.best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            self.best_epoch = epoch\n",
    "            improved = True\n",
    "        else:\n",
    "            # Am√©lioration si la loss diminue OU l'accuracy augmente significativement\n",
    "            if val_loss < self.best_loss - self.min_delta or val_acc > self.best_acc + 0.5:\n",
    "                self.best_loss = val_loss\n",
    "                self.best_acc = val_acc\n",
    "                self.best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "                self.best_epoch = epoch\n",
    "                self.counter = 0\n",
    "                improved = True\n",
    "            else:\n",
    "                self.counter += 1\n",
    "        \n",
    "        if improved:\n",
    "            print(\"‚úÖ New best model saved!\")\n",
    "        else:\n",
    "            print(f\"üìà EarlyStopping counter: {self.counter}/{self.patience}\")\n",
    "            \n",
    "        if self.counter >= self.patience:\n",
    "            self.early_stop = True\n",
    "            print(\"üõë Early stopping triggered!\")\n",
    "            \n",
    "        return self.early_stop\n",
    "    \n",
    "    def restore_best_model(self, model):\n",
    "        if self.restore_best_weights and self.best_model_state is not None:\n",
    "            model.load_state_dict(self.best_model_state)\n",
    "            print(f\"‚úÖ Best weights restored from epoch {self.best_epoch}!\")\n",
    "            print(f\"üèÜ Best validation accuracy: {self.best_acc:.2f}%\")\n",
    "\n",
    "class AudioAugmentation:\n",
    "    \"\"\"Augmentation audio plus contr√¥l√©e\"\"\"\n",
    "    def __init__(self, strength=0.6):\n",
    "        self.strength = strength\n",
    "        self.sample_rate = config.sample_rate\n",
    "        \n",
    "    def __call__(self, waveform):\n",
    "        if random.random() > 1 - self.strength:\n",
    "            # Time stretching (plus subtil)\n",
    "            if random.random() > 0.5:\n",
    "                rate = random.uniform(0.9, 1.1)\n",
    "                try:\n",
    "                    waveform_stretched = F.interpolate(\n",
    "                        waveform.unsqueeze(0),\n",
    "                        size=int(waveform.shape[-1] * rate),\n",
    "                        mode='linear',\n",
    "                        align_corners=False\n",
    "                    ).squeeze(0)\n",
    "                    \n",
    "                    # Recadrage/padding\n",
    "                    if waveform_stretched.shape[-1] > waveform.shape[-1]:\n",
    "                        waveform = waveform_stretched[..., :waveform.shape[-1]]\n",
    "                    else:\n",
    "                        waveform = F.pad(waveform_stretched, \n",
    "                                       (0, waveform.shape[-1] - waveform_stretched.shape[-1]))\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # Gaussian noise (plus l√©ger)\n",
    "            if random.random() > 0.6:\n",
    "                noise_level = random.uniform(0.001, 0.005)\n",
    "                noise = torch.randn_like(waveform) * noise_level\n",
    "                waveform = waveform + noise\n",
    "            \n",
    "            # Random gain (plus subtil)\n",
    "            if random.random() > 0.4:\n",
    "                gain = random.uniform(0.85, 1.15)\n",
    "                waveform = waveform * gain\n",
    "            \n",
    "            # Polarity inversion\n",
    "            if random.random() > 0.8:\n",
    "                waveform = -waveform\n",
    "                \n",
    "        return waveform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31f47412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: Dataset avec Weighted Sampling\n",
    "# =============================================================================\n",
    "class SpeechCommandsDataset(Dataset):\n",
    "    def __init__(self, subset='training', apply_augmentation=False):\n",
    "        self.data_path = r\"D:\\voice_processing\\data\\SpeechCommands\\speech_commands_v0.02\"\n",
    "        \n",
    "        # Chargement des fichiers selon le subset\n",
    "        if subset == 'training':\n",
    "            with open(os.path.join(self.data_path, 'validation_list.txt'), 'r') as f:\n",
    "                val_files = set(f.read().splitlines())\n",
    "            with open(os.path.join(self.data_path, 'testing_list.txt'), 'r') as f:\n",
    "                test_files = set(f.read().splitlines())\n",
    "            \n",
    "            all_files = []\n",
    "            for class_name in os.listdir(self.data_path):\n",
    "                class_path = os.path.join(self.data_path, class_name)\n",
    "                if os.path.isdir(class_path) and not class_name.startswith('_'):\n",
    "                    for file in os.listdir(class_path):\n",
    "                        if file.endswith('.wav'):\n",
    "                            rel_path = os.path.join(class_name, file)\n",
    "                            if rel_path not in val_files and rel_path not in test_files:\n",
    "                                all_files.append((os.path.join(class_path, file), class_name))\n",
    "            \n",
    "            self.samples = all_files\n",
    "            \n",
    "        elif subset == 'validation':\n",
    "            with open(os.path.join(self.data_path, 'validation_list.txt'), 'r') as f:\n",
    "                val_files = f.read().splitlines()\n",
    "            \n",
    "            self.samples = []\n",
    "            for rel_path in val_files:\n",
    "                class_name = rel_path.split('/')[0]\n",
    "                full_path = os.path.join(self.data_path, rel_path)\n",
    "                if os.path.exists(full_path):\n",
    "                    self.samples.append((full_path, class_name))\n",
    "                    \n",
    "        elif subset == 'testing':\n",
    "            with open(os.path.join(self.data_path, 'testing_list.txt'), 'r') as f:\n",
    "                test_files = f.read().splitlines()\n",
    "            \n",
    "            self.samples = []\n",
    "            for rel_path in test_files:\n",
    "                class_name = rel_path.split('/')[0]\n",
    "                full_path = os.path.join(self.data_path, rel_path)\n",
    "                if os.path.exists(full_path):\n",
    "                    self.samples.append((full_path, class_name))\n",
    "        \n",
    "        # Classes et mapping\n",
    "        self.labels = sorted(list(set([label for _, label in self.samples])))\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(self.labels)}\n",
    "        self.idx_to_label = {idx: label for label, idx in self.label_to_idx.items()}\n",
    "        self.apply_augmentation = apply_augmentation\n",
    "        self.augment = AudioAugmentation(strength=config.aug_strength)\n",
    "        \n",
    "        print(f\"üìä {subset}: {len(self.samples)} samples, {len(self.labels)} classes\")\n",
    "        \n",
    "        # Transformations audio\n",
    "        self.transform = T.MelSpectrogram(\n",
    "            sample_rate=config.sample_rate,\n",
    "            n_fft=config.n_fft,\n",
    "            hop_length=config.hop_length,\n",
    "            n_mels=config.n_mels,\n",
    "            f_min=20,\n",
    "            f_max=8000,\n",
    "            power=2.0\n",
    "        )\n",
    "        self.to_db = T.AmplitudeToDB(stype='power', top_db=80)\n",
    "        \n",
    "        # SpecAugment avec param√®tres optimis√©s\n",
    "        self.time_mask = T.TimeMasking(time_mask_param=15)\n",
    "        self.freq_mask = T.FrequencyMasking(freq_mask_param=8)\n",
    "    \n",
    "    def get_class_weights(self):\n",
    "        \"\"\"Calcule les poids des classes pour l'√©quilibrage\"\"\"\n",
    "        labels = [self.label_to_idx[label] for _, label in self.samples]\n",
    "        class_weights = compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(labels),\n",
    "            y=labels\n",
    "        )\n",
    "        return torch.FloatTensor(class_weights)\n",
    "    \n",
    "    def get_sample_weights(self):\n",
    "        \"\"\"Retourne les poids pour chaque √©chantillon\"\"\"\n",
    "        class_weights = self.get_class_weights()\n",
    "        sample_weights = []\n",
    "        for _, label in self.samples:\n",
    "            class_idx = self.label_to_idx[label]\n",
    "            sample_weights.append(class_weights[class_idx])\n",
    "        return sample_weights\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.samples[idx]\n",
    "        \n",
    "        # Charger l'audio\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "        \n",
    "        # Resampling si n√©cessaire\n",
    "        if sample_rate != config.sample_rate:\n",
    "            resampler = T.Resample(sample_rate, config.sample_rate)\n",
    "            waveform = resampler(waveform)\n",
    "        \n",
    "        # Mono si st√©r√©o\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "        \n",
    "        # Normalisation robuste\n",
    "        waveform = waveform / (waveform.abs().max() + 1e-8)\n",
    "        \n",
    "        # Augmentation\n",
    "        if self.apply_augmentation and random.random() > 0.3:\n",
    "            waveform = self.augment(waveform)\n",
    "        \n",
    "        # Padding/truncation\n",
    "        current_length = waveform.shape[1]\n",
    "        if current_length < config.target_length:\n",
    "            waveform = F.pad(waveform, (0, config.target_length - current_length))\n",
    "        else:\n",
    "            if self.apply_augmentation:\n",
    "                start = random.randint(0, current_length - config.target_length)\n",
    "            else:\n",
    "                start = (current_length - config.target_length) // 2\n",
    "            waveform = waveform[:, start:start + config.target_length]\n",
    "        \n",
    "        # Mel Spectrogram\n",
    "        mel_spec = self.transform(waveform)\n",
    "        mel_spec_db = self.to_db(mel_spec)\n",
    "        \n",
    "        # SpecAugment pour l'entra√Ænement\n",
    "        if self.apply_augmentation and random.random() > 0.5:\n",
    "            mel_spec_db = self.time_mask(mel_spec_db)\n",
    "            if random.random() > 0.5:\n",
    "                mel_spec_db = self.freq_mask(mel_spec_db)\n",
    "        \n",
    "        # Normalisation par instance\n",
    "        mel_spec_db = (mel_spec_db - mel_spec_db.mean()) / (mel_spec_db.std() + 1e-8)\n",
    "        \n",
    "        # 3 channels pour MobileNetV3\n",
    "        mel_spec_3ch = mel_spec_db.repeat(3, 1, 1)\n",
    "        \n",
    "        label_idx = self.label_to_idx[label]\n",
    "        \n",
    "        return mel_spec_3ch, label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eb5a6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: Mod√®le Optimis√© avec Attention\n",
    "# =============================================================================\n",
    "class SqueezeExcitation(nn.Module):\n",
    "    \"\"\"Module SE pour am√©liorer les features\"\"\"\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = F.adaptive_avg_pool2d(x, 1).view(b, c)\n",
    "        y = F.relu(self.fc1(y))\n",
    "        y = torch.sigmoid(self.fc2(y)).view(b, c, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "class MobileNetV3AudioClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=35, freeze_layers=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Backbone MobileNetV3 Large pr√©-entra√Æn√©\n",
    "        self.backbone = timm.create_model(\n",
    "            'mobilenetv3_large_100',\n",
    "            pretrained=True,\n",
    "            in_chans=3,\n",
    "            num_classes=0,  # Pas de classifieur\n",
    "            global_pool=''\n",
    "        )\n",
    "        \n",
    "        # Obtenir la dimension des features\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.randn(1, 3, 128, 32)\n",
    "            features = self.backbone(dummy)\n",
    "            feature_dim = features.shape[1]\n",
    "        \n",
    "        # Geler les premi√®res couches\n",
    "        self._freeze_layers(freeze_layers)\n",
    "        \n",
    "        # Attention suppl√©mentaire\n",
    "        self.se = SqueezeExcitation(feature_dim, reduction=16)\n",
    "        \n",
    "        # Pooling adaptatif\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Classifieur optimis√©\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(config.classifier_dropout),\n",
    "            nn.Linear(feature_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ MobileNetV3 cr√©√© avec {freeze_layers} couches gel√©es\")\n",
    "        \n",
    "    def _freeze_layers(self, num_layers):\n",
    "        \"\"\"Geler les premi√®res couches du backbone\"\"\"\n",
    "        layers_frozen = 0\n",
    "        \n",
    "        for name, param in self.backbone.named_parameters():\n",
    "            if 'conv_stem' in name or 'bn1' in name or 'blocks.0' in name or 'blocks.1' in name:\n",
    "                if layers_frozen < num_layers:\n",
    "                    param.requires_grad = False\n",
    "                    layers_frozen += 1\n",
    "        \n",
    "        print(f\"‚ùÑÔ∏è {layers_frozen} couches initiales gel√©es\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Extraction des features\n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        # Attention\n",
    "        x = self.se(x)\n",
    "        \n",
    "        # Pooling et classification\n",
    "        x = self.global_pool(x)\n",
    "        x = x.flatten(1)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "450db145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Toutes les fonctions optimis√©es sont charg√©es!\n",
      "\n",
      "üí° Am√©liorations principales:\n",
      "   - Weighted sampling pour √©quilibrage des classes\n",
      "   - Mixed Precision Training (AMP)\n",
      "   - Learning rate warm-up\n",
      "   - Attention mechanism (Squeeze-Excitation)\n",
      "   - Augmentation audio contr√¥l√©e\n",
      "   - Early stopping am√©lior√©\n",
      "   - Batch size augment√© pour stabilit√©\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: Training avec Mixed Precision et Warm-up\n",
    "# =============================================================================\n",
    "class LabelSmoothCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, smoothing=0.1, weight=None):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "    \n",
    "    def forward(self, x, target):\n",
    "        log_probs = F.log_softmax(x, dim=-1)\n",
    "        nll_loss = -log_probs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "        nll_loss = nll_loss.squeeze(1)\n",
    "        \n",
    "        if self.weight is not None:\n",
    "            nll_loss = nll_loss * self.weight[target]\n",
    "        \n",
    "        smooth_loss = -log_probs.mean(dim=-1)\n",
    "        loss = (1 - self.smoothing) * nll_loss + self.smoothing * smooth_loss\n",
    "        return loss.mean()\n",
    "\n",
    "def get_lr_scheduler_with_warmup(optimizer, num_warmup_epochs, num_epochs):\n",
    "    \"\"\"Learning rate scheduler avec warm-up\"\"\"\n",
    "    def lr_lambda(epoch):\n",
    "        if epoch < num_warmup_epochs:\n",
    "            # Warm-up lin√©aire\n",
    "            return (epoch + 1) / num_warmup_epochs\n",
    "        else:\n",
    "            # Cosine annealing apr√®s warm-up\n",
    "            progress = (epoch - num_warmup_epochs) / (num_epochs - num_warmup_epochs)\n",
    "            return 0.5 * (1 + np.cos(np.pi * progress))\n",
    "    \n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device, scaler=None):\n",
    "    \"\"\"Entra√Ænement pour une epoch avec AMP\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc='üöÄ Training')\n",
    "    for data, target in pbar:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed Precision Training\n",
    "        if scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "        \n",
    "        accuracy = 100. * correct / total\n",
    "        pbar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Accuracy': f'{accuracy:.2f}%'\n",
    "        })\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    \"\"\"Validation\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(loader, desc='üìä Validation'):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total\n",
    "\n",
    "print(\"‚úÖ Toutes les fonctions optimis√©es sont charg√©es!\")\n",
    "print(\"\\nüí° Am√©liorations principales:\")\n",
    "print(\"   - Weighted sampling pour √©quilibrage des classes\")\n",
    "print(\"   - Mixed Precision Training (AMP)\")\n",
    "print(\"   - Learning rate warm-up\")\n",
    "print(\"   - Attention mechanism (Squeeze-Excitation)\")\n",
    "print(\"   - Augmentation audio contr√¥l√©e\")\n",
    "print(\"   - Early stopping am√©lior√©\")\n",
    "print(\"   - Batch size augment√© pour stabilit√©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bc0c0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Chargement des datasets optimis√©s...\n",
      "üìä training: 105829 samples, 35 classes\n",
      "üìä validation: 9981 samples, 35 classes\n",
      "üìä testing: 11005 samples, 35 classes\n",
      "\n",
      "‚öñÔ∏è Poids des classes calcul√©s pour l'√©quilibrage\n",
      "‚úÖ Donn√©es charg√©es avec sampler √©quilibr√©!\n",
      "üìä R√©sum√©:\n",
      "   - Batch size: 32\n",
      "   - √âchantillons d'entra√Ænement: 105,829\n",
      "   - √âchantillons de validation: 9,981\n",
      "   - √âchantillons de test: 11,005\n",
      "   - Classes: 35\n",
      "‚ùÑÔ∏è 3 couches initiales gel√©es\n",
      "‚úÖ MobileNetV3 cr√©√© avec 3 couches gel√©es\n",
      "\n",
      "üìä Informations du mod√®le:\n",
      "   - Param√®tres totaux: 5,083,043\n",
      "   - Param√®tres entra√Ænables: 5,082,579\n",
      "   - Param√®tres gel√©s: 464\n",
      "   - Pourcentage gel√©: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 6: Chargement des Donn√©es avec Weighted Sampling\n",
    "# =============================================================================\n",
    "print(\"üîß Chargement des datasets optimis√©s...\")\n",
    "\n",
    "# Chargement des datasets\n",
    "train_dataset = SpeechCommandsDataset(subset='training', apply_augmentation=True)\n",
    "val_dataset = SpeechCommandsDataset(subset='validation', apply_augmentation=False)\n",
    "test_dataset = SpeechCommandsDataset(subset='testing', apply_augmentation=False)\n",
    "\n",
    "num_classes = len(train_dataset.labels)\n",
    "\n",
    "# Calcul des poids de classe\n",
    "class_weights = train_dataset.get_class_weights().to(device)\n",
    "print(f\"\\n‚öñÔ∏è Poids des classes calcul√©s pour l'√©quilibrage\")\n",
    "\n",
    "# Weighted Random Sampler pour √©quilibrer les classes\n",
    "sample_weights = train_dataset.get_sample_weights()\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "# DataLoaders avec sampler √©quilibr√©\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config.batch_size,\n",
    "    sampler=sampler,  # Utilisation du sampler au lieu de shuffle\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Donn√©es charg√©es avec sampler √©quilibr√©!\")\n",
    "print(f\"üìä R√©sum√©:\")\n",
    "print(f\"   - Batch size: {config.batch_size}\")\n",
    "print(f\"   - √âchantillons d'entra√Ænement: {len(train_dataset):,}\")\n",
    "print(f\"   - √âchantillons de validation: {len(val_dataset):,}\")\n",
    "print(f\"   - √âchantillons de test: {len(test_dataset):,}\")\n",
    "print(f\"   - Classes: {num_classes}\")\n",
    "\n",
    "# Cr√©ation du mod√®le optimis√©\n",
    "model = MobileNetV3AudioClassifier(num_classes=num_classes, freeze_layers=3).to(device)\n",
    "\n",
    "# Affichage des informations du mod√®le\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "frozen_params = total_params - trainable_params\n",
    "\n",
    "print(f\"\\nüìä Informations du mod√®le:\")\n",
    "print(f\"   - Param√®tres totaux: {total_params:,}\")\n",
    "print(f\"   - Param√®tres entra√Ænables: {trainable_params:,}\")\n",
    "print(f\"   - Param√®tres gel√©s: {frozen_params:,}\")\n",
    "print(f\"   - Pourcentage gel√©: {frozen_params/total_params*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdec656c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ D√©marrage de l'entra√Ænement optimis√©...\n",
      "\n",
      "üéØ Configuration d'entra√Ænement:\n",
      "   - Epochs: 100\n",
      "   - Warm-up epochs: 5\n",
      "   - Early Stopping patience: 15\n",
      "   - Mixed Precision: Activ√©\n",
      "   - Weighted Sampling: Activ√©\n",
      "   - Class Weighting: Activ√©\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üìÖ Epoch 1/100\n",
      "======================================================================\n",
      "üìà Learning Rates: Backbone=1.00e-05, Head=1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üöÄ Training:   0%|          | 0/3308 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 7: ENTRA√éNEMENT OPTIMIS√â\n",
    "# =============================================================================\n",
    "print(\"\\nüöÄ D√©marrage de l'entra√Ænement optimis√©...\\n\")\n",
    "\n",
    "# Fonction de perte avec poids de classe\n",
    "criterion = LabelSmoothCrossEntropyLoss(\n",
    "    smoothing=config.label_smoothing,\n",
    "    weight=class_weights\n",
    ")\n",
    "\n",
    "# Optimizer avec param√®tres group√©s\n",
    "param_groups = [\n",
    "    {'params': model.backbone.parameters(), 'lr': config.learning_rate * 0.1},  # LR plus faible pour backbone\n",
    "    {'params': model.se.parameters(), 'lr': config.learning_rate},\n",
    "    {'params': model.classifier.parameters(), 'lr': config.learning_rate}\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    param_groups,\n",
    "    lr=config.learning_rate,\n",
    "    weight_decay=config.weight_decay,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "# Scheduler avec warm-up\n",
    "scheduler = get_lr_scheduler_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_epochs=config.warmup_epochs,\n",
    "    num_epochs=config.num_epochs\n",
    ")\n",
    "\n",
    "# Mixed Precision Scaler\n",
    "scaler = torch.cuda.amp.GradScaler() if config.use_amp else None\n",
    "\n",
    "# Early Stopping optimis√©\n",
    "early_stopping = EarlyStopping(patience=15, min_delta=0.0005, restore_best_weights=True)\n",
    "\n",
    "# Historique d'entra√Ænement\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [],\n",
    "    'val_loss': [], 'val_acc': [],\n",
    "    'learning_rates': []\n",
    "}\n",
    "\n",
    "best_val_acc = 0\n",
    "best_epoch = 0\n",
    "\n",
    "print(f\"üéØ Configuration d'entra√Ænement:\")\n",
    "print(f\"   - Epochs: {config.num_epochs}\")\n",
    "print(f\"   - Warm-up epochs: {config.warmup_epochs}\")\n",
    "print(f\"   - Early Stopping patience: {early_stopping.patience}\")\n",
    "print(f\"   - Mixed Precision: {'Activ√©' if config.use_amp else 'D√©sactiv√©'}\")\n",
    "print(f\"   - Weighted Sampling: Activ√©\")\n",
    "print(f\"   - Class Weighting: Activ√©\")\n",
    "print()\n",
    "\n",
    "for epoch in range(config.num_epochs):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìÖ Epoch {epoch+1}/{config.num_epochs}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Learning rates actuels\n",
    "    current_lrs = [param_group['lr'] for param_group in optimizer.param_groups]\n",
    "    print(f\"üìà Learning Rates: Backbone={current_lrs[0]:.2e}, Head={current_lrs[2]:.2e}\")\n",
    "    \n",
    "    # Phase d'entra√Ænement\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, scaler)\n",
    "    \n",
    "    # Phase de validation\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Mise √† jour de l'historique\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['learning_rates'].append(current_lrs[2])  # LR du head\n",
    "    \n",
    "    # Affichage des r√©sultats\n",
    "    print(f\"\\nüìä R√©sultats Epoch {epoch+1}:\")\n",
    "    print(f\"   Train ‚Üí Loss: {train_loss:.4f} | Accuracy: {train_acc:.2f}%\")\n",
    "    print(f\"   Val   ‚Üí Loss: {val_loss:.4f} | Accuracy: {val_acc:.2f}%\")\n",
    "    \n",
    "    # Calcul de l'am√©lioration\n",
    "    if len(history['val_acc']) > 1:\n",
    "        acc_diff = val_acc - history['val_acc'][-2]\n",
    "        loss_diff = val_loss - history['val_loss'][-2]\n",
    "        print(f\"   Œî Accuracy: {acc_diff:+.2f}% | Œî Loss: {loss_diff:+.4f}\")\n",
    "    \n",
    "    # V√©rification Early Stopping\n",
    "    if early_stopping(val_loss, val_acc, model, epoch+1):\n",
    "        print(f\"\\nüõë Early Stopping d√©clench√© √† l'epoch {epoch + 1}!\")\n",
    "        break\n",
    "    \n",
    "    # Sauvegarde du meilleur mod√®le\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'config': config.__dict__,\n",
    "            'history': history,\n",
    "            'class_weights': class_weights.cpu()\n",
    "        }, 'best_mobilenetv3_optimized.pth')\n",
    "        print(f\"   üíæ Meilleur mod√®le sauvegard√©! (Accuracy: {val_acc:.2f}%)\")\n",
    "    \n",
    "    # Ajustement du learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # D√©gel progressif (apr√®s warm-up)\n",
    "    if epoch == config.warmup_epochs * 2:\n",
    "        print(\"\\nüîì D√©gel de couches suppl√©mentaires du backbone...\")\n",
    "        for name, param in model.backbone.named_parameters():\n",
    "            if 'blocks.2' in name or 'blocks.3' in name:\n",
    "                param.requires_grad = True\n",
    "        trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f\"   Nouveaux param√®tres entra√Ænables: {trainable:,}\")\n",
    "\n",
    "# Restauration du meilleur mod√®le\n",
    "early_stopping.restore_best_model(model)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"üéâ ENTRA√éNEMENT TERMIN√â!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"üèÜ Meilleure accuracy de validation: {best_val_acc:.2f}%\")\n",
    "print(f\"üìÖ Meilleure epoch: {best_epoch}\")\n",
    "print(f\"üìà Epochs totales: {epoch + 1}\")\n",
    "\n",
    "# Sauvegarde finale\n",
    "torch.save(model.state_dict(), 'final_mobilenetv3_optimized.pth')\n",
    "print(\"üíæ Mod√®le final sauvegard√©!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bd0e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: √âVALUATION D√âTAILL√âE\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä √âVALUATION FINALE DU MOD√àLE\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# √âvaluation sur le test set\n",
    "test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "print(f\"üéØ Performance sur le test set:\")\n",
    "print(f\"   - Loss: {test_loss:.4f}\")\n",
    "print(f\"   - Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "# M√©triques d√©taill√©es par classe\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in tqdm(test_loader, desc='üîç Analyse d√©taill√©e'):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(data)\n",
    "        \n",
    "        probs = F.softmax(output, dim=1)\n",
    "        preds = output.argmax(dim=1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(target.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "# Calcul des m√©triques\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "accuracy = accuracy_score(all_targets, all_preds)\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    all_targets, all_preds, average=None\n",
    ")\n",
    "\n",
    "print(f\"\\nüìà M√©triques Globales:\")\n",
    "print(f\"   - Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"   - F1-Score (macro): {np.mean(f1):.4f}\")\n",
    "print(f\"   - Precision (macro): {np.mean(precision):.4f}\")\n",
    "print(f\"   - Recall (macro): {np.mean(recall):.4f}\")\n",
    "\n",
    "# Top-5 et Bottom-5 classes\n",
    "class_f1 = list(zip(train_dataset.labels, f1, support))\n",
    "class_f1_sorted = sorted(class_f1, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"\\nüèÜ Top-5 Classes (meilleur F1-Score):\")\n",
    "for i, (label, score, supp) in enumerate(class_f1_sorted[:5], 1):\n",
    "    print(f\"   {i}. {label:15s} ‚Üí F1: {score:.4f} (n={supp})\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è Bottom-5 Classes (F1-Score le plus faible):\")\n",
    "for i, (label, score, supp) in enumerate(class_f1_sorted[-5:], 1):\n",
    "    print(f\"   {i}. {label:15s} ‚Üí F1: {score:.4f} (n={supp})\")\n",
    "\n",
    "# Analyse de l'√©quilibre\n",
    "print(f\"\\n‚öñÔ∏è Analyse de l'√©quilibre des performances:\")\n",
    "f1_std = np.std(f1)\n",
    "f1_range = np.max(f1) - np.min(f1)\n",
    "print(f\"   - √âcart-type F1: {f1_std:.4f}\")\n",
    "print(f\"   - Range F1: {f1_range:.4f}\")\n",
    "print(f\"   - Classes avec F1 > 0.90: {sum(f1 > 0.90)}/{len(f1)}\")\n",
    "print(f\"   - Classes avec F1 < 0.70: {sum(f1 < 0.70)}/{len(f1)}\")\n",
    "\n",
    "# Rapport de classification d√©taill√©\n",
    "print(f\"\\nüìã Rapport de Classification Complet:\")\n",
    "print(classification_report(\n",
    "    all_targets, all_preds,\n",
    "    target_names=train_dataset.labels,\n",
    "    digits=3\n",
    "))\n",
    "\n",
    "print(\"\\n‚úÖ √âvaluation termin√©e!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c32c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Export ONNX du meilleur mod√®le\n",
    "print(\"\\nüì§ Export du mod√®le en format ONNX...\")\n",
    "\n",
    "# Assurer que le mod√®le est en mode √©valuation\n",
    "model.eval()\n",
    "\n",
    "# Cr√©er un exemple d'input\n",
    "dummy_input = torch.randn(1, 3, config.n_mels, config.target_length // config.hop_length + 1).to(device)\n",
    "\n",
    "# Export ONNX\n",
    "onnx_path = \"mobilenetv3_speech_commands.onnx\"\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_path,\n",
    "    export_params=True,\n",
    "    opset_version=12,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'}\n",
    "    },\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Mod√®le export√© avec succ√®s: {onnx_path}\")\n",
    "print(f\"üìä Taille du fichier ONNX: {os.path.getsize(onnx_path) / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# V√©rification de l'export ONNX\n",
    "try:\n",
    "    import onnx\n",
    "    import onnxruntime as ort\n",
    "    \n",
    "    onnx_model = onnx.load(onnx_path)\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    print(\"‚úÖ Mod√®le ONNX v√©rifi√© avec succ√®s!\")\n",
    "    \n",
    "    # Test avec ONNX Runtime\n",
    "    ort_session = ort.InferenceSession(onnx_path)\n",
    "    \n",
    "    # Test de pr√©diction\n",
    "    dummy_np = dummy_input.cpu().numpy()\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: dummy_np}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    \n",
    "    print(\"‚úÖ ONNX Runtime test r√©ussi!\")\n",
    "    print(f\"üìã Informations ONNX:\")\n",
    "    print(f\"   - Input shape: {ort_session.get_inputs()[0].shape}\")\n",
    "    print(f\"   - Output shape: {ort_session.get_outputs()[0].shape}\")\n",
    "    print(f\"   - Opset version: {onnx_model.opset_import[0].version}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è ONNX non install√©, impossible de v√©rifier le mod√®le\")\n",
    "    print(\"üí° Installer avec: pip install onnx onnxruntime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796a9acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Visualisations et sauvegarde finale\n",
    "print(\"\\nüé® Cr√©ation des visualisations...\")\n",
    "\n",
    "# Graphiques de performance\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss', linewidth=2, alpha=0.8)\n",
    "plt.plot(history['val_loss'], label='Val Loss', linewidth=2, alpha=0.8)\n",
    "plt.axvline(x=best_epoch-1, color='r', linestyle='--', alpha=0.7, label=f'Best Epoch ({best_epoch})')\n",
    "plt.title('√âvolution des Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history['train_acc'], label='Train Accuracy', linewidth=2, alpha=0.8)\n",
    "plt.plot(history['val_acc'], label='Val Accuracy', linewidth=2, alpha=0.8)\n",
    "plt.axvline(x=best_epoch-1, color='r', linestyle='--', alpha=0.7, label=f'Best Epoch ({best_epoch})')\n",
    "plt.title('√âvolution de l\\'Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Learning Rate\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history['learning_rates'], label='Learning Rate', linewidth=2, color='purple', alpha=0.8)\n",
    "plt.title('√âvolution du Learning Rate')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_metrics_mobilenetv3.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(f'Matrice de Confusion - MobileNetV3\\nAccuracy: {test_acc:.2f}%')\n",
    "plt.colorbar()\n",
    "\n",
    "# Afficher seulement quelques labels pour la lisibilit√©\n",
    "if len(train_dataset.labels) > 20:\n",
    "    tick_marks = np.arange(0, len(train_dataset.labels), max(1, len(train_dataset.labels)//20))\n",
    "    plt.xticks(tick_marks, [train_dataset.labels[i] for i in tick_marks], rotation=45)\n",
    "    plt.yticks(tick_marks, [train_dataset.labels[i] for i in tick_marks])\n",
    "else:\n",
    "    tick_marks = np.arange(len(train_dataset.labels))\n",
    "    plt.xticks(tick_marks, train_dataset.labels, rotation=45)\n",
    "    plt.yticks(tick_marks, train_dataset.labels)\n",
    "\n",
    "plt.xlabel('Pr√©diction')\n",
    "plt.ylabel('V√©rit√© terrain')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_mobilenetv3.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Sauvegarde de l'historique\n",
    "import json\n",
    "history_serializable = {k: [float(x) if isinstance(x, (np.floating, float)) else x for x in v] \n",
    "                       for k, v in history.items()}\n",
    "\n",
    "with open('training_history.json', 'w') as f:\n",
    "    json.dump(history_serializable, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úÖ Toutes les op√©rations sont termin√©es!\")\n",
    "print(\"üìÅ Fichiers cr√©√©s:\")\n",
    "print(f\"   - best_mobilenetv3_model_complete.pth (mod√®le complet avec historique)\")\n",
    "print(f\"   - final_mobilenetv3_model.pth (mod√®le final)\")\n",
    "print(f\"   - mobilenetv3_speech_commands.onnx (mod√®le ONNX)\")\n",
    "print(f\"   - training_metrics_mobilenetv3.png (graphiques)\")\n",
    "print(f\"   - confusion_matrix_mobilenetv3.png (matrice de confusion)\")\n",
    "print(f\"   - training_history.json (historique d'entra√Ænement)\")\n",
    "\n",
    "print(f\"\\nüéØ R√©sultats finaux:\")\n",
    "print(f\"   - Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"   - Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"   - Best Epoch: {best_epoch}\")\n",
    "print(f\"   - Total Epochs: {epoch + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8068b72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorche_windows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
